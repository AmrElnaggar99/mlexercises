{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sentiment Classification\n",
    "\n",
    "The goal of this example is to classify movie reviews as positive or negative sentiments. This can be used to classify for example social media postings.\n",
    "\n",
    "Parts of the example are taken from [1]. The code used the Glove model [2].\n",
    "\n",
    "- [1] [https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras/](https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras/)\n",
    "- [2] [https://nlp.stanford.edu/pubs/glove.pdf](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "\n",
    "\n",
    "Citation GloVe [4] and dataset [5]:\n",
    "```\n",
    "[4] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.\n",
    "\n",
    "[5] Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher, Learning Word Vectors for Sentiment Analysis, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, June 2011, Portland, Oregon, USA, Association for Computational Linguistics, http://www.aclweb.org/anthology/P11-1015\n",
    "\n",
    "```\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import of modules\n",
    "#\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import zipfile\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense, SpatialDropout1D\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Turn off error messages\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# GPU support\n",
    "#\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Path and URL constants\n",
    "#\n",
    "urlDataSource = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "localExtractionFolder = 'data/moviereviews'\n",
    "localDataArchive = localExtractionFolder + '/aclImdb_v1.tar.gz'\n",
    "textData = localExtractionFolder + '/aclImdb/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load data from URL\n",
    "#\n",
    "def download_dataset(url,dataset_file_path,extraction_directory):\n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)\n",
    "    if os.path.exists(dataset_file_path):\n",
    "        print(\"archive already downloaded.\")\n",
    "    else:\n",
    "        print(\"started loading archive from url {}\".format(url))\n",
    "        filename, headers = urlretrieve(url, dataset_file_path)\n",
    "        print(\"finished loading archive from url {} to {}\".format(url,filename))\n",
    "\n",
    "def extract_dataset(dataset_file_path, extraction_directory):\n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)\n",
    "    if (dataset_file_path.endswith(\"tar.gz\") or dataset_file_path.endswith(\".tgz\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:gz\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    elif (dataset_file_path.endswith(\"tar\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Download if not already loaded\n",
    "#\n",
    "download_dataset(urlDataSource,localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Extract from archive\n",
    "#\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are the files organized on the file system?\n",
    "\n",
    "Take a quick look how the files are organized on the file system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Collect data from the files\n",
    "#\n",
    "def load_texts_labels_from_folders(path, folders):\n",
    "    print('scanning path {}'.format(path))\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(folders):\n",
    "        print('scanning {}'.format(idx))\n",
    "        for fname in glob(os.path.join(path, label, '*.*')):\n",
    "            texts.append(open(fname, 'r').read())\n",
    "            labels.append(idx)\n",
    "    return texts, np.array(labels).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Loading of positive and negative examples\n",
    "#\n",
    "classes = ['neg','pos']\n",
    "x_train,y_train = load_texts_labels_from_folders( textData + 'train', classes)\n",
    "x_test,y_test = load_texts_labels_from_folders( textData + 'test', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First checks on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check shapes of data\n",
    "#\n",
    "len(x_train),len(y_train),len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check data types\n",
    "#\n",
    "(type(x_train),type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check classes\n",
    "#\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print some negative examples\n",
    "#\n",
    "for index in range (0,1):\n",
    "    print(x_train[index])\n",
    "    print(\"label {}\".format(y_train[index]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print some positive examples\n",
    "#\n",
    "for index in range (13001,13002):\n",
    "    print(x_train[index])\n",
    "    print(\"label {}\".format(y_train[index]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Clean text (1 points)\n",
    "\n",
    "Write a function called preprocess_text(text) which takes a text piece and **cleans out** the following artifacts:\n",
    "\n",
    "1. html tags, but leave text between tags intact\n",
    "1. punctuations and numbers\n",
    "1. single characters\n",
    "1. multiple white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result: the cleaner\n",
    "#\n",
    "def preprocess_text(sen):\n",
    "    sentence = sen\n",
    "    # ...\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Clean all texts\n",
    "#\n",
    "x_train_clean = []\n",
    "for review in x_train:\n",
    "    x_train_clean.append(preprocess_text(review))\n",
    "    \n",
    "x_test_clean = []\n",
    "for review in x_test:\n",
    "    x_test_clean.append(preprocess_text(review))  \n",
    "    \n",
    "x_test = x_test_clean\n",
    "x_train = x_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find mean text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Count length of text strings\n",
    "#\n",
    "textLength = []\n",
    "for index in range (0,len(x_train)):\n",
    "    textLength.append(len(x_train[index]))\n",
    "\n",
    "#\n",
    "# Plot histogram\n",
    "#\n",
    "plt.hist(textLength)\n",
    "lengthArray = np.array(textLength)\n",
    "print('text character length mean {}'.format(np.mean(lengthArray)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert words into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split text up into tokens\n",
    "#\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True, oov_token='unknwn')\n",
    "#\n",
    "# Train tokenizer\n",
    "#\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert words into integer sequences\n",
    "#\n",
    "x_train_v = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_v = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check original sentence\n",
    "print(x_train[0], len(x_train[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check token sequence\n",
    "print(x_train_v[0], len(x_train_v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse tokens to text for check\n",
    "text = tokenizer.sequences_to_texts([x_train_v[0]])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Count length of integer sequences (aka word sequences)\n",
    "#\n",
    "textLength = []\n",
    "for index in range (0,len(x_train_v)):\n",
    "    textLength.append(len(x_train_v[index]))\n",
    "\n",
    "#\n",
    "# Plot histogram\n",
    "#\n",
    "plt.hist(textLength)\n",
    "lengthArray = np.array(textLength)\n",
    "print('vectorized length mean {}'.format(np.mean(lengthArray)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get size of vocabulary of tokenizer\n",
    "#\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('count of words {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: select a proper maximum length of text (1 point)\n",
    "\n",
    "Set maxlen to a suitable value for the text length. Longer text sequences are cut off, shorter sequences are padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxlen = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pad sequences\n",
    "#\n",
    "x_train_v = pad_sequences(x_train_v, padding='post', maxlen=maxlen)\n",
    "x_test_v = pad_sequences(x_test_v, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Glove models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloveUrl = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "gloveExtractionFolder = 'data/glove'\n",
    "gloveDataArchive = gloveExtractionFolder + '/glove.6B.zip'\n",
    "\n",
    "#\n",
    "# Select 100 dims for embedding space\n",
    "#\n",
    "gloveData = gloveExtractionFolder + '/' + 'glove.6B.100d.txt'\n",
    "gloveDims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_dataset(dataset_file_path, extraction_directory):  \n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)        \n",
    "    zip = zipfile.ZipFile(dataset_file_path)\n",
    "    zip.extractall(path=extraction_directory)        \n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Execute download\n",
    "#\n",
    "if ( not os.path.exists(gloveData)):\n",
    "    download_dataset(gloveUrl,gloveDataArchive,gloveExtractionFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Unzip glove\n",
    "#\n",
    "if ( not os.path.exists(gloveData)):\n",
    "    unzip_dataset(gloveDataArchive,gloveExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load glove embeddings into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create dict of glove vectors for each word in glove model\n",
    "#\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open(gloveData, encoding=\"utf8\")\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copy glove vectors for each word in the tokenizer model\n",
    "#\n",
    "embedding_matrix = np.zeros((vocab_size, gloveDims))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print some examples of glove vectors for words (1 point)\n",
    "\n",
    "Select some random word from the tokenizer and print the glove vectors for those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result:\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple model\n",
    "\n",
    "**Note** how the embedding_matrix is used in the first layer to embed the token integers into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNNModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, gloveDims, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createNNModel()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_v, y_train, batch_size=128, epochs=12, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_v, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test loss:\", score[0])\n",
    "print(\"test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResults(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save a model for later use\n",
    "#\n",
    "from keras.models import model_from_json\n",
    "\n",
    "prefix = 'results/02_'\n",
    "modelName = prefix + \"model.json\"\n",
    "weightName = prefix + \"model.h5\"\n",
    "\n",
    "\n",
    "def handle_model(model,save_model):\n",
    "    # set to True if the model should be saved\n",
    "    if save_model:\n",
    "        model_json = model.to_json()\n",
    "        with open( modelName , \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights( weightName )\n",
    "        print(\"saved model to disk as {} {}\".format(modelName,weightName))\n",
    "        return model\n",
    "    \n",
    "\n",
    "    # load model (has to be saved before, is not part of git)    \n",
    "    if not save_model:\n",
    "        json_file = open(modelName, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(weightName)\n",
    "        print(\"loaded model from disk\")        \n",
    "        return loaded_model\n",
    "    \n",
    "#\n",
    "# Load or save model\n",
    "#\n",
    "model = handle_model(model,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Improved model based on LSTMs (2 points)\n",
    "\n",
    "The previous model reaches around 70% of test accuracy. This is not sufficient for your customer. So we need a better model. Research the internet for sentiment analysis models using LSTMs and implement a better version of the model based on this information.\n",
    "\n",
    "1. Implement an LSTM based model version for sentiment analysis (you can also use a different model if you find publications for it)\n",
    "1. Document the sources you have found\n",
    "1. Test the model in comparison to the older model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result: new model\n",
    "#\n",
    "def createLSTMModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = createLSTMModel()\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(x_train_v, y_train, batch_size=128, epochs=30, verbose=1, validation_split=0.2)\n",
    "score = model2.evaluate(x_test_v, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test loss:\", score[0])\n",
    "print(\"test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResults(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = handle_model(model2,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Replace 100 d model with 300 d model for embedding (2 points)\n",
    "\n",
    "Try better embedding model with 300 dimensions instead of the 100 dimension model. Load the different Glove weights, update the vector matrix for the embedding layer and the model structure for the better Glove model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result: Code and accuracy of new model\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Replace Glove model with BERT model vectors (2 points)\n",
    "\n",
    "Try to replace Glove with a BERT model. This is no easy task. Research the internet for tutorials about this goal and write down all changes you would need to implement for this change (concept only, implementation optional).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result: Concept for switching form Glove to BERT\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance = x_test_clean[56]\n",
    "print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    \n",
    "    instance = tokenizer.texts_to_sequences(text)\n",
    "    flat_list = []\n",
    "    for sublist in instance:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "\n",
    "    flat_list = [flat_list]\n",
    "    instance = pad_sequences(flat_list, padding='post', maxlen=maxlen)\n",
    "    sentiment = model2.predict(instance)\n",
    "    \n",
    "    comment = 'meh'\n",
    "    if sentiment > 0.85:\n",
    "        comment = 'very good'\n",
    "    elif sentiment > 0.75:\n",
    "        comment = 'good'\n",
    "    elif sentiment > 0.50:\n",
    "        comment = 'moderate'\n",
    "    return sentiment,comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"I simply don't like this film.\"\n",
    "print ( sentiment(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"I hate this film.\"\n",
    "print ( sentiment(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"I love this film.\"\n",
    "print ( sentiment(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = x_test_clean[13000]\n",
    "print ( sentiment(test1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
